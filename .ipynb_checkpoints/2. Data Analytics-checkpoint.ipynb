{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# An Introduction to Data Science\n",
    "\n",
    "## Steve Cassidy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Defining Data Science - Analysis Methods\n",
    "\n",
    "Once we have our data, one goal of DS is to perform some kind of analysis to try to support a hypothesis or tell a story. Analysis methods include:\n",
    "\n",
    "- summary statistics\n",
    "- data smoothing, dimensionality reduction, feature selection\n",
    "- visualisation\n",
    "- statistical hypothesis testing\n",
    "\n",
    "This will draw on you basic statistical knowledge and extend it in a few areas.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "\n",
    "Analysis methods are seeking to find meaning in the data we look at. We need to be able to present large quantities of data in a succinct way so that we can **see the meaning** in the data; observe trends; look for patterns. \n",
    "\n",
    "Statistical tests allow us to be rigourous in whether we accept or reject an hypothesis: did it just happen by chance or is it a real effect we are observing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Technology\n",
    "\n",
    "You will be learning to use [Python](https://python.org/) for this analysis with the associated statistical and graphical tools.  It is also common to see the [R language](https://r-project.org/) used for Data Science - you'll see that if you do the Statistics units in the DS major.  \n",
    "\n",
    "We'll use Git and [Github](https://github.com/MQCOMP257) to host and share our work and track changes.\n",
    "\n",
    "We're using [Jupyter Notebooks](https://jupyter-notebook.readthedocs.io/en/stable/) to carry out analysis and generate documented presentations of results.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Defining Data Science - Modelling and Prediction\n",
    "\n",
    "A big part of Data Science is about going beyond the observations that you have in your data to be able to predict future outcomes or make judgements about unseen data based on past observations. \n",
    "\n",
    "**Modelling** is the use of past data to build a computational model of a system.   That model can then be used in different ways: to classify unseen data (is it spam) attach labels to data (face recognition, image labelling) or predict future trends (where will the stock market go next).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Modelling Techniques \n",
    "We use many techniques for building models, we'll learn a few in this unit: \n",
    "\n",
    "- **Linear Regression** works for simple systems where the relationship between observeable variables is linear, it can be extended to deal with more complex relationships\n",
    "- **Logistic Regression** allows us to predict categorical outcomes (spam or ham, good investment or bad)\n",
    "- **Clustering** algorithms find patterns in data and show us groupings that might not be obvious \n",
    "- **Classification** algorithms allow us to label unseen data based on past observations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Machine Learning\n",
    "\n",
    "All of these are really examples of **Machine Learning** to some degree.  They rely on seeing past examples of data that has known outcomes and enable us to build models that can predict outcomes for new observations.   The difference between the models that we will see and full on Deep Learning models is one of complexity.  \n",
    "\n",
    "The harder the problem you are trying to build a model of (eg. speech recognition, language understanding) the more input parameters you generally have and the more **degrees of freedom** in your model are needed to account for the complex system you are learning.   Many degrees of freedom requires more data to train and longer, more complex training process.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Jupyter Notebooks\n",
    "\n",
    "The [Jupyter](https://jupyter.org) is in part a response to this need to provide more easily replicated analysis.  You'll see how it enables us to create a single document that contains both the commentary on the data and analysis and the code that generates the results.  Sharing a notebook as part of the product of your research can enhance the reproducibility of your work, which makes it better science. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Github\n",
    "\n",
    "The motivation for using Github is twofold.\n",
    "\n",
    "- Using Git to track changes provides another trace of evidence for what we did\n",
    "- Might help someone understand the train of thought in the experiment\n",
    "- Using Github to **publish** the repository makes it available to all\n",
    "- Others can clone the repository and run **your code**"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
